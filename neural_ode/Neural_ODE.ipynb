{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e21a61b-747e-4454-ace5-638a76912de4",
   "metadata": {},
   "source": [
    "## Basic Neural Network Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e75b27-bbba-45ea-bf8e-a0320d5e34cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training: \n",
      "[[0.00505119]\n",
      " [0.00505119]\n",
      " [0.99494905]\n",
      " [0.99494905]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ------------------- Dataset ------------------\n",
    "# input features\n",
    "X = np.array([ [0,1],\n",
    "               [0,1],\n",
    "               [1,0],\n",
    "               [1,0] ])\n",
    "\n",
    "# output labels\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "# ------------ Activation Function -------------\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    "\n",
    "\n",
    "# ----------------- Training ------------------\n",
    "\n",
    "# seed random numbers to make calculations\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "synapse_0 = 2*np.random.random((2,1)) - 1\n",
    "\n",
    "# Number of iterations of forward pass and backward pass\n",
    "for iter in range(10000):\n",
    "\n",
    "    # forward propagation\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0,synapse_0))\n",
    "    # print(layer_1)\n",
    "    \n",
    "    # how much error did we make?\n",
    "    layer_1_error = layer_1 - y\n",
    "\n",
    "    # backpropagation\n",
    "    # multiply how much we missed by the\n",
    "    # slope of the sigmoid at the values in L1\n",
    "    layer_1_delta = layer_1_error * sigmoid_output_to_derivative(layer_1)\n",
    "    synapse_0_derivative = np.dot(layer_0.T, layer_1_delta)\n",
    "    \n",
    "    # update weights\n",
    "    synapse_0 -= synapse_0_derivative\n",
    "\n",
    "print(\"Output After Training: \")\n",
    "print(layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350438c-4389-4a3f-b630-4b484337c4fe",
   "metadata": {},
   "source": [
    "This code demonstrates a simple implementation of a neural network that uses a single layer to perform binary classification using a sigmoid activation function. Let's go through the code step by step:\r\n",
    "\r\n",
    "Importing Libraries: The code starts by importing the necessary library, NumPy, which is widely used for numerical computations in Python.\r\n",
    "\r\n",
    "Dataset: The input features X represent a dataset with four samples, each having two features. The input values are binary (0 or 1). The output labels y are binary as well, indicating the desired classification results for each input sample.\r\n",
    "\r\n",
    "Activation Function (Sigmoid): Two functions are defined for working with the sigmoid activation function. The sigmoid function takes an input x and computes the sigmoid of that input using the formula 1 / (1 + exp(-x)). The sigmoid_output_to_derivative function computes the derivative of the sigmoid output with respect to its input.\r\n",
    "\r\n",
    "Training:\r\n",
    "\r\n",
    "Random Seed: The random seed is set to 1 to ensure that random number generation is deterministic across different runs. This is just a good practice to make the results reproducible.\r\n",
    "\r\n",
    "Initializing Weights: The weights synapse_0 are initialized randomly with values between -1 and 1. These weights will be learned and updated during training to make accurate predictions.\r\n",
    "\r\n",
    "Iterations (Forward and Backward Passes): The training loop runs for 10000 iterations. In each iteration:\r\n",
    "\r\n",
    "Forward Propagation: The input layer layer_0 is set to the input features X. The output of the hidden layer layer_1 is computed by applying the sigmoid activation function to the dot product of layer_0 and synapse_0.\r\n",
    "\r\n",
    "Error Calculation: The difference between the predicted values in layer_1 and the actual output labels y is computed as layer_1_error.\r\n",
    "\r\n",
    "Backpropagation: The error is backpropagated to adjust the weights. The gradient of the error with respect to the weights is computed using the product of the error and the derivative of the sigmoid output.\r\n",
    "\r\n",
    "Weight Update: The weights synapse_0 are updated by subtracting the computed weight derivatives synapse_0_derivative.\r\n",
    "\r\n",
    "Output After Training: After training, the final output of the neural network is printed, representing the predicted binary classification results.\r\n",
    "\r\n",
    "This code essentially implements a single-layer neural network with sigmoid activation to perform binary classification. It demonstrates the basic principles of forward propagation, error calculation, and backpropagation for updating the weights to minimize the error over iterations. However, it's important to note that this example is quite simple and lacks certain optimizations and advanced features that are typically found in more complex neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02fc06-f713-45e4-9c1d-3d7b02cf5fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661de6fd-f2ad-4227-bb6a-ceffefbbb7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68660bf2-4b92-4010-8feb-5f56e8ea667c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ed864-bd3a-4540-9ace-8a1397d629b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517ce46-6336-4ce0-a01c-41dc4898022c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
