# Neural Networks and Deep Learning
This lecture is written from application perspective, rather than the theory perspective. Nevertheless, I have tried to take care of the following:
1. Easy explanations
2. Rigorous mathematics
3. Easy code
4. Easy to understand and relatable projects.

### Contents

| S.No | Topic | Divisions |
|---|---|---|
|1| History | 1.1 Where does intelligence and learning come from? <br/> 1.2 How to model an artificial neuron after biological? |
|2| A single neuron | 2.1 Mathematics <br/> 2.2 Forward pass and training <br/> 2.3 Activation functions |
|3| Multi-layer perceptron and Feed Forward Neural Networks |  |
|4| Problems associated with traditional deep learning and solutions |  |
|5| Convolutional Neural Networks | 5.1 Images, how they are defined and created? <br/> 5.2 How are different pixels related and how to extract features? <br/> 5.3 What is a convolution? <br/> Through a project. <br/> 5.4 How to define a convolutional neural network? <br/> 5.5 How to train a convolutional network? <br/> 5.6 How to forward pass? <br/> 5.7 How to predict? <br/> 5.8 Why convolutional neural networks are not enough? Local relations not global. Only spatial relations not temporal. <br/> 5.9 Architecture of famous CNN network YOLO. <br/> 5.10 What are 3D convolutions? |
|6| Recurrent Neural Networks | 6.1 Why temporal info is important? <br/> 6.2 How to handle time series data? <br/> Through a project. <br/> 6.3 How to define? <br/> 6.4 How to train? <br/> 6.4 Forward pass <br/> 6.5 Gated RNNs most useful. LSTMs and GRUs.|
|7| Problems with these approaches and solutions | 7.1 Residual Neural Networks |