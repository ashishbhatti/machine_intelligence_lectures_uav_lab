{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb1e7d9-1f66-4d74-b96d-f994119774b9",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97dd472-1ced-4163-8c91-22e255b1d4b2",
   "metadata": {},
   "source": [
    "## 1. History"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6d9e654-98d3-40c5-98ef-d9bd59c9a5d9",
   "metadata": {},
   "source": [
    "**Where does intelligence and learning come from?** \\\n",
    "In order to mimic human intelligence, researchers started looking at the neuronal circuitry in the brain. Human brain has close to 90 billion neurons, interconnected in neuronal pathways. The cells in brain are different from other cells in the body. \n",
    "\n",
    "The so called neurons look like this:\n",
    "| Image of human neuron | Image of neurons in macaque |\n",
    "| --- | --- |\n",
    "|![Photo by Bob Jacobs, Colorado College.](./resources/golgi2.jpg)| ![Photo by BrainMaps.org](./resources/smi32-macaque.jpg) |\n",
    "| This is the picture of an actual human neuron (neocortical pyramidal neuron, stained via Golgi technique). <br/> [Photo by Bob Jacobs, Colorado College.](https://en.wikipedia.org/wiki/Golgi%27s_method#/media/File:GolgiStainedPyramidalCell.jpg) <br/> Golgi's method stains a limited number of cells at random using silver chromate reaction.  It is still not known why a certain cell would undergo the reaction while a cell right next to it would not. The result is that the morphology of the cells can be clearly seen without contamination from nearby dendrites from other cells. Read more at [1](https://cellularscale.blogspot.com/2012/03/seeing-cells-nissl-and-golgi-together.html),[2](https://embryo.asu.edu/pages/neuron-doctrine-1860-1895). | SMI32-immunoreactive pyramidal neuron in medial prefrontal cortex of macaque. <br/> [Photo by BrainMaps.org](https://brainmaps.org/index.php?p=screenshots)|\n",
    "\n",
    "The structure of a neuron is the following: \\\n",
    "![Photo by BruceBlaus](./resources/blausen_multipolarneuron.png) \\\n",
    "The neuron is essentially a computation unit which performs the following operations: \n",
    "1. **Input reception**: receives input from other neurons the synapses located on its dendrites, these inputs can be excitatory (increases the likelihood of neuron firing) or inhibitory (decreasing the likelihood).\n",
    "2. **Signal integration**: the cell body integrates these incoming inputs and computes a response. \n",
    "3. **Signal transmission**: If this response exceeds a certain threshold, the neuron generates an electrical signal called action potential which travels via its axon.\n",
    "4. **Output release**: When the action potential reaches the end of the axon, it triggers the release of neurotransmitters in the synaptic gap. These neurotransmitters then bind to the receptors on the dendrites of adjascent neurons, thereby transmitting the signal.\n",
    "\n",
    "It is important to note that this is a simplification. The neurons used in neural networks today are modelled after this simplified explanation, which the neuroscientists from 1950s were familiar with. Still, the neural networks perform really well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b451e-af35-40c9-9669-0bb498e23232",
   "metadata": {},
   "source": [
    "**How to model an artificial neuron after a biological neuron?** \\\n",
    "An artificial neuron should perform these 4 operations as well. \n",
    "![Photo by ashishbhatti](./resources/artificial_neuron.png)\n",
    "\n",
    "An artificial neuron does the following:\n",
    "1. It receives input from multiple other neurons, say n.\n",
    "   It multiplies each input with a weight, increasing / decreasing input significance.\n",
    "   (Trying to mimic the excitatory / inhibitory effect).\n",
    "3. It sums these weighed inputs and adds a bias, also known as threshold.\n",
    "   $$result, z = \\sum_{i=1}^{n} w_ix_i  + b$$\n",
    "4. The result is passed on to an activation function, which produces an output.\n",
    "   $$y = f(z)$$\n",
    "6. The output is released to other neurons or as general output.\n",
    "\n",
    "**The weights are learned during the training process.**\n",
    "\n",
    "Note that, if you use logistic function (sigmoid function) as the activation function, the above neuron is exactly same as logistic regression. As a matter of fact, the logistic regression model, or rather its generalization for multiclass classification, called the softmax regression model, is a standard unit in a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb71b4-6e53-4312-b5dd-c499b97b6cfa",
   "metadata": {},
   "source": [
    "## 2. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e62bc-e682-40dd-9aad-e6cb30cace7e",
   "metadata": {},
   "source": [
    "A neural network with a single neuron is called a perceptron. In this section we will develop the mathematical model of a single neuron and we will implement it in code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e23ff-5328-4acd-b619-d442f6bc4168",
   "metadata": {},
   "source": [
    "**Mathematics of a single neuron**\n",
    "$$z = \\sum_{i=1}^{n} w_ix_i  + b$$\n",
    "$$y = f(z)$$\n",
    "\n",
    "In the above figure we define a neuron which performs above 2 operations, where:\n",
    "- $x_i \\in \\Real $ are inputs at different synapses.\n",
    "- $w_i \\in \\R$ are the synaptic weights.\n",
    "- $b \\in \\R$ is the neuron's bias or threshold.\n",
    "- $z = w_1x_1 + w_2x_2 + w_3x_3 + ... + w_nx_n$ is the summed value of weighted inputs at the neuron's body. Note $z \\in \\R$.\n",
    "- $f : \\R \\arrow \\R$ is an activation function for the axon, which takes weighted sum as input. The output produced by this activation function $y$, is the output at the axon terminal.\n",
    "\n",
    "In vector form we can write the above equations as:\n",
    "$$y = f(z) = f(\\textbf{w}.\\textbf{x} + b)$$\n",
    "where $\\textbf{w} \\in \\R3$ is the synaptic weight vector, $\\textbf{x} \\in \\R3$ is the input vector, and $.$ is the dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7673e-3aea-4251-b462-0a38264d779f",
   "metadata": {},
   "source": [
    "**What is an activation function?** \\\n",
    "The activation function is essentially a mathematical function which takes weighted sum as input and computes a response based on that. This tries to mimic the generation of action potential in a neuron, depending on the threshold.\n",
    "\n",
    "We can use any kind of function as activation function. Some popular ones are:\n",
    "\n",
    "| S.No | Activation Function | Description |\n",
    "| --- | --- | --- |\n",
    "|1| Identity | This is when there is no activation function. <br/> Here nothing is done to the weighted input, it is passed as the output as it is. |\n",
    "|2| Binary Step | The output of this function is either 0 or 1. <br/> With this our neuron can be used as an ON-OFF switch. |\n",
    "|3| Logistic (aka Sigmoid or Soft Step) | Restricts the output between [0,1]. |\n",
    "|4| tanh | Hyperbolic tangent. Restricts the output between [-1,1]. | \n",
    "|5| ReLU | Rectified Linear Unit <br/>   |\n",
    "|6| Gaussian |  |\n",
    "|7| Softmax |  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96321b3-13e4-4300-93c1-bffff3114499",
   "metadata": {},
   "source": [
    "**How much a single neuron is useful?** \\\n",
    "This is similar to asking the question that how much a single logic gate is useful. We know that a single logic gate can perfom simple calculation, but when arranged in a network, it becomes a computer.\n",
    "\n",
    "We can see that our neuron takes inputs and produces outputs, and that is it. If the weights and bias are set to certain values, depending on the problem, the output can be useful, otherwise we just have a random number generator.\n",
    "\n",
    "Thus in order to make a neuron useful, we need to train it. In order to train our neuron we need a separate trainer program which can do the following:\n",
    "- evaluate the neuron's performance throughout the training\n",
    "- can improve neuron's performance if it makes mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34280d83-b933-4bcc-ab3f-5c30e803869a",
   "metadata": {},
   "source": [
    "**How to train a single neuron?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df35b4c-a15a-4196-a1bf-232e33393796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bae2f-160e-44b5-bcec-bef4da5449e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106de3fc-bb65-4b03-92ad-ed6b5b62335f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba15096-2fd0-421a-b3b4-a995e0d0c4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d5dea-27df-4d5c-95c7-a78d94b69429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68cbee-f492-42eb-a68a-928e8bb511da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac952d2b-aa07-4eb4-81e8-22c8f6154aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bafc7e-e44b-44fb-bdf1-cfa597917ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31453442-5906-4f90-bc2c-8c4954a51ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c91ea-e645-450b-8b1a-95f4b58dcc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
