{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "242bc260-df49-4063-951d-7b8eb7dcf366",
   "metadata": {},
   "source": [
    "# Understanding ViT Tracker from Opencv\n",
    "\n",
    "The ViT Tracker was implemented by Pengyu Liu as part of GSoC project 2023. \\\n",
    "This tracker is based on this paper.\n",
    "\n",
    "This document is to understand the various aspects of the code of Vision Transformer Tracking `vttrack`.\n",
    "1. Figuring out which model they used.\n",
    "   - VOTS 2023 results paper.\n",
    "   - OpenCV Zoo repo and comments\n",
    "   - The model elements from the trained onnx file.\n",
    "2. Explaining the code parts\n",
    "   - ROI selector using `selectROI()` function of OpenCV\n",
    "   - Custom made ROI selector\n",
    "   - Integrating the model for gimbal control via laptop\n",
    "   - Integrating the model for gimbal control via jetson\n",
    "   - Training the same model on custom dataset\n",
    "   - Training a new model on the custom dataset\n",
    "3. Writing the paper on the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354072f9-564c-4848-9637-a15f28f1efdd",
   "metadata": {},
   "source": [
    "### 1. Figuring out which model they used.\n",
    "\n",
    "#### Visual Object Tracking and Segmentation Challenge 2023:\n",
    "Their description from the VOT 2023 results from following paper.\\\r\n",
    "Kristan, M., et al, \"The First Visual Object Tracking Segmentation VOTS2023 Challenge Results,\" in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2023, pp. 1796-1818 [Link.](https://openaccess.thecvf.com/content/ICCV2023W/VOTS/html/Kristan_The_First_Visual_Object_Tracking_Segmentation_VOTS2023_Challenge_Results_ICCVW_2023_paper.htm\n",
    "\n",
    "Steps:\n",
    "1. \n",
    "We fine-tuned the weights generated using the MAE[19] method on the tracking dataset \\\n",
    "2.  We used VIT Large model. First, both the template and search regions were patch embedded, then concatenated together for feature extraction and fusion through transformer block structure. Finally the fused features are output to the classification and regression heads to complete the generation of bounding boxes \\\n",
    "3.  We apply a Hanning window on the output of the classification head to utilize the motion information of the object \\\n",
    "4.  After that, we retrieve the output of the regression head at the position with the highest confidence and output the bounding box. We used Segment Anything Model (SAM)[25] as the model for outputting masks. When the confidence value outputted by the tracker is very low, it is considered that the target is no longer in the image, and an empty mask is outpute..\n",
    "\n",
    "\n",
    "#### OpenCV Zoo issue comment\n",
    "*@arielkantorovich* asked: \\\n",
    "Hi, I want to ask you about the weights [object_tracking_vittrack_2023sep.onnx](https://github.com/opencv/opencv_zoo/blob/main/models/object_tracking_vittrack/object_tracking_vittrack_2023sep.onnx) the VitTracker is implementation of the papper Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework?\r\n",
    "Do you train on your own data or do you take weights from the GitHub OSTrack and change to ONNX I am asking because I want to try maybe another weights.\r\n",
    "Thank you for your help \n",
    "\n",
    "@lpylpy0514 replied: \\\n",
    "I used the same training dataset as OSTrack, but without using pre-trained weights. In terms of model implementation, I replaced patch embedding for small models. For this, please refer to Levit: a vision transformer in convnet's clothing for faster inference.:)d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a86bb-ab95-47e8-9589-b4a887f58946",
   "metadata": {},
   "source": [
    "### 2. Understanding the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0027cec2-4a17-480f-862f-5e76ff515d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected region:  (190, 249, 104, 100)\n"
     ]
    }
   ],
   "source": [
    "# how to obtain the region of interest in a frame\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "original = cv2.imread('test.jpg')\n",
    "img = original.copy()\n",
    "img = cv2.resize(img, None, (0,0), 0.5, 0.5)\n",
    "roi = cv2.selectROI('ROI', img)\n",
    "cv2.destroyWindow('ROI')\n",
    "print(\"Selected region: \",roi)\n",
    "\n",
    "# display the region selected\n",
    "# roi is in (x,y,w,h) format\n",
    "cv2.rectangle(img, (roi[0], roi[1]), (roi[0] + roi[2], roi[1] + roi[3]), (255,255,255), 1)\n",
    "cv2.imshow('Selected Region', img)\n",
    "if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94fa53b5-9989-41d0-941c-9c52fd8193f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 211, 175, 184)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def select_roi(img_path):\n",
    "    roi_data = {'roi_start': (0, 0), 'roi_end': (0, 0), 'selecting_roi': False, 'display_img': None}\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            roi_data['roi_start'] = (x, y)\n",
    "            roi_data['roi_end'] = (x, y)\n",
    "            roi_data['selecting_roi'] = True\n",
    "\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            roi_data['roi_end'] = (x, y)\n",
    "            roi_data['selecting_roi'] = False\n",
    "            cv2.rectangle(roi_data['display_img'], roi_data['roi_start'], roi_data['roi_end'], (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Select ROI\", roi_data['display_img'])\n",
    "\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and roi_data['selecting_roi']:\n",
    "            roi_data['roi_end'] = (x, y)\n",
    "            roi_data['display_img'] = img.copy()\n",
    "            cv2.rectangle(roi_data['display_img'], roi_data['roi_start'], roi_data['roi_end'], (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Select ROI\", roi_data['display_img'])\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    roi_data['display_img'] = img.copy()\n",
    "\n",
    "    cv2.namedWindow(\"Select ROI\")\n",
    "    cv2.setMouseCallback(\"Select ROI\", mouse_callback)\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Select ROI\", roi_data['display_img'])\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('c') and not roi_data['selecting_roi']:\n",
    "            roi = img[min(roi_data['roi_start'][1], roi_data['roi_end'][1]):max(roi_data['roi_start'][1], roi_data['roi_end'][1]),\n",
    "                      min(roi_data['roi_start'][0], roi_data['roi_end'][0]):max(roi_data['roi_start'][0], roi_data['roi_end'][0])]\n",
    "            cv2.imshow(\"Cropped ROI\", roi)\n",
    "            cv2.waitKey(0)\n",
    "            break\n",
    "\n",
    "        elif key == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    return (\n",
    "        min(roi_data['roi_start'][0], roi_data['roi_end'][0]), \n",
    "        min(roi_data['roi_start'][1], roi_data['roi_end'][1]), \n",
    "        abs(roi_data['roi_start'][0] - roi_data['roi_end'][0]), \n",
    "        abs(roi_data['roi_start'][1] - roi_data['roi_end'][1])\n",
    "    )    \n",
    "           \n",
    "\n",
    "# Example usage\n",
    "roi = select_roi('test.jpg')\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ea05600-8531-46a3-a2b6-f9cef705be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a317c1b-1709-4a68-80db-fb961793b3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
