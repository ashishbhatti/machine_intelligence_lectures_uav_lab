{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af20db3-93d1-4bf5-965b-fe1286044827",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045a438-61ae-4d83-ae33-97105833c529",
   "metadata": {},
   "source": [
    "### 1. Using Haar Cascades in OpenCV\n",
    "\n",
    "Haar cascades are a machine learning-based object detection method that predates the widespread use of deep learning. They are a cascade of classifiers that use a series of simple image features to identify objects or regions of interest in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b59e9c9f-7158-402e-82c4-fd64b4b65b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Load the pre-trained Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize the camera (assuming Raspberry Pi camera module)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Variables for FPS calculation\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert the frame to grayscale (Haar cascades work on grayscale images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform face detection\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle, bounding box. (x,y) is the upper left edge of box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Draw dot at center of bounding box (x + w//2, y + h//2)\n",
    "        cv2.circle(frame, (x + w//2, y + h//2), 3, (0, 255, 0), -1)  # Green dot\n",
    "\n",
    "        # Display coordinates at the top of rectangle\n",
    "        cv2.putText(frame, f'x: {x}, y: {y}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # Calculate FPS\n",
    "    fps_frame_count += 1\n",
    "    if fps_frame_count >= 1:\n",
    "        fps_end_time = time.time()\n",
    "        fps = fps_frame_count / (fps_end_time - fps_start_time)\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = fps_end_time\n",
    "        \n",
    "        # Print FPS\n",
    "        # print(\"FPS: {:.2f}\".format(fps))\n",
    "        cv2.putText(frame, \"FPS: {:.2f}\".format(fps), (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    \n",
    "    # Display the frame with detected faces\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    \n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the OpenCV window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bcdab4-bba8-40a0-8d20-763b29718b6d",
   "metadata": {},
   "source": [
    "On CPU it is giving over 20 fps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7738363-1923-43b6-af3b-96eba38d9370",
   "metadata": {},
   "source": [
    "### 2. Using cvlib's face_detect "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c1898-3351-4f80-9242-ff96c816c405",
   "metadata": {},
   "source": [
    "The `cvlib.detect_face` function in the `cvlib` library uses a pre-trained deep learning model for face detection. The model is based on a Single Shot Multibox Detector (SSD), which is a popular architecture for object detection tasks. It uses a pre-trained caffe model, with a modified res-net backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce0e4a8-cbf5-4d6c-a55d-1535042a211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvlib\n",
    "import time\n",
    "\n",
    "# Initialize the camera (assuming default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Variables for FPS calculation\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Perform face detection\n",
    "    faces, confidences = cvlib.detect_face(frame)\n",
    "\n",
    "    # print(faces.type)\n",
    "\n",
    "    # Loop over detected faces and draw rectangles\n",
    "    for face in faces:\n",
    "        (startX, startY, endX, endY) = face\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "        # # Draw dot at center of bounding box (x + w//2, y + h//2)\n",
    "        # coordinateX = (startX + endX)//2\n",
    "        # coordinateY = (startY + endY)//2\n",
    "        # cv2.circle(frame, (coordinateX, coordinateY), 3, (255, 255, 255), -1)  # White dot\n",
    "        # # print(f\"x: {coordinateX}, y: {coordinateY}\")\n",
    "    \n",
    "        # Draw dot at the neck, that is below of bounding box\n",
    "        # neck position\n",
    "        coordinateX = (startX + endX) // 2\n",
    "        coordinateY = endY + int(0.25*(endY - startY))\n",
    "        cv2.circle(frame, (coordinateX, coordinateY), 3, (0, 255, 0), -1)  # Green dot\n",
    "\n",
    "    # Calculate FPS\n",
    "    fps_frame_count += 1\n",
    "    if fps_frame_count >= 1:\n",
    "        fps_end_time = time.time()\n",
    "        fps = fps_frame_count / (fps_end_time - fps_start_time)\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = fps_end_time\n",
    "\n",
    "        # Print FPS\n",
    "        cv2.putText(frame, \"FPS: {:.2f}\".format(fps), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with detected faces and FPS\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the OpenCV window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29771ec-1929-4654-9198-ae160e2ca1b7",
   "metadata": {},
   "source": [
    "On CPU giving over 20 FPS, and can detect faces better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bb486-c342-4e9e-a0d4-9c9242037358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
